stages:
- name: run_lm_experiment
  corpus_type:
  - wikitext2
  - wikitext103
  - penntreebank
  embedding_type:
  - glove.6B.50d
  - glove.6B.100d
  batch_size: 128
  max_init_param: 0.05
  max_norm: 5
  number_of_layers: 2
  sequence_length: 30
  sequence_step_size: 10
  dropout_probability: 0.1
  device: gpu
  model_type:
  - lstm
  - lstm
  learning_rate_decay: 0.85
  learning_rate: 1
  number_of_epochs: 2
  min_freq: 5
  lstm_configs:
    - default
    - att-emb
- name: rnn_training_comparison
  lstm_configs:
    - default
    - att-emb