batch_size: 80
embedding_size: 100
hidden_size: 100
learning_rate: 0.005
learning_rate_decay: 0.95
max_init_param: 0.05
max_norm: 9
number_of_layers: 2
sequence_length: 30
dropout_probability: 0.5
lstm_configuration: var-emb
device: gpu
